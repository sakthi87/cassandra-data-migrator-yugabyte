# Configuration Analysis: 3K+ IOPS Achievements

## Summary

Based on the analysis of `cursor_cassandra_and_yugabyte_database.md`, here are the configurations that achieved **more than 3,000 IOPS**:

---

## üèÜ Configuration 1: 3,159 IOPS (Average)

### Configuration Details:
- **Partitions:** 40 (`spark.cdm.perfops.numParts=40`)
- **Record Count:** 250,000 records
- **Duration:** 79.15 seconds (~1 minute 19 seconds)
- **Average Throughput:** 3,159 IOPS
- **Peak Throughput:** 3,930 IOPS
- **Success Rate:** 100% (40/40 partitions)

### Key Settings:
```properties
# Performance Settings
spark.cdm.perfops.numParts=40
spark.cdm.perfops.batchSize=25
spark.cdm.connect.target.yugabyte.batchSize=50
spark.cdm.perfops.fetchSizeInRows=2000

# Connection Pool
spark.cdm.connect.target.yugabyte.pool.maxSize=3
spark.cdm.connect.target.yugabyte.pool.minSize=1
# Total connections: 40 √ó 3 = 120 connections

# Spark Configuration
--master local[20]
--driver-memory 3G
--executor-memory 1G
--executor-cores 1
```

### Performance Metrics:
- **Average:** 3,159 records/second
- **Peak:** 3,930 records/second
- **Records per minute:** ~189,516
- **Partitions:** 40/40 (100% success)

---

## üèÜ Configuration 2: 3,192 IOPS (Peak)

### Configuration Details:
- **Partitions:** 24 (Aggressive configuration)
- **Record Count:** 250,000 records
- **Duration:** 97 seconds (1.6 minutes)
- **Average Throughput:** 2,554 IOPS
- **Peak Throughput:** 3,192 IOPS
- **Success Rate:** 100% (24/24 partitions)

### Key Settings:
```properties
# Performance Settings
spark.cdm.perfops.numParts=24
spark.cdm.connect.target.yugabyte.batchSize=100
spark.cdm.perfops.fetchSizeInRows=5000

# Connection Pool
spark.cdm.connect.target.yugabyte.pool.maxSize=5
spark.cdm.connect.target.yugabyte.pool.minSize=2
# Total connections: 24 √ó 5 = 120 connections
```

### Performance Metrics:
- **Average:** 2,554 IOPS
- **Peak:** 3,192 IOPS
- **Status:** Complete

---

## Comparison Table

| Configuration | Partitions | Batch Size | Fetch Size | Average IOPS | Peak IOPS | Duration | Record Count |
|---------------|------------|------------|------------|--------------|-----------|----------|--------------|
| **Best Average** | 40 | 50 | 2000 | **3,159** | 3,930 | 79s | 250,000 |
| **Best Peak** | 24 | 100 | 5000 | 2,554 | **3,192** | 97s | 250,000 |
| **Current Best** | 28 | 100 | 5000 | **2,874** | - | 87s | 250,000 |

---

## Key Findings

1. **40 Partitions Configuration:**
   - Achieved the highest **average** throughput: 3,159 IOPS
   - Fastest completion time: 79 seconds
   - Used smaller batch size (50) and fetch size (2000)
   - Connection pool: 3 per partition (120 total)

2. **24 Partitions Configuration:**
   - Achieved the highest **peak** throughput: 3,192 IOPS
   - Used larger batch size (100) and fetch size (5000)
   - Connection pool: 5 per partition (120 total)
   - Average was lower (2,554 IOPS) due to startup/teardown overhead

3. **28 Partitions (Current):**
   - Achieved 2,874 IOPS average
   - Best balance between average and peak performance
   - Fastest recent completion: 87 seconds

---

## Recommendations

To achieve **3,000+ IOPS consistently**, use:

### Option 1: 40 Partitions (Best Average)
```properties
spark.cdm.perfops.numParts=40
spark.cdm.connect.target.yugabyte.batchSize=50
spark.cdm.perfops.fetchSizeInRows=2000
spark.cdm.connect.target.yugabyte.pool.maxSize=3
```

### Option 2: 24-28 Partitions (Best Peak)
```properties
spark.cdm.perfops.numParts=24-28
spark.cdm.connect.target.yugabyte.batchSize=100
spark.cdm.perfops.fetchSizeInRows=5000
spark.cdm.connect.target.yugabyte.pool.maxSize=5
```

---

## Notes

- All tests used **250,000 records**
- Both configurations achieved 100% success rate
- Connection pool size was consistent (120 total connections)
- The 40-partition configuration had the best average performance
- The 24-partition configuration had the best peak performance
