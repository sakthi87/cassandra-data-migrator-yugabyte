# =============================================================================
# CDM Migration Properties - Transaction Table Test WITH AUDIT FIELDS
# =============================================================================
# This file is configured for testing migration from Cassandra to YugabyteDB
# with Constant Columns feature to populate audit fields
# Source: transaction_datastore.dda_pstd_fincl_txn_cnsmr_by_accntnbr
# Target: transaction_datastore.dda_pstd_fincl_txn_cnsmr_by_accntnbr
# =============================================================================

# =============================================================================
# ORIGIN (CASSANDRA) CONNECTION
# =============================================================================
spark.cdm.connect.origin.host=localhost
spark.cdm.connect.origin.port=9043
spark.cdm.connect.origin.username=cassandra
spark.cdm.connect.origin.password=cassandra

# =============================================================================
# TARGET (YUGABYTEDB YSQL) CONNECTION
# =============================================================================
spark.cdm.connect.target.yugabyte.host=localhost
spark.cdm.connect.target.yugabyte.port=5433
spark.cdm.connect.target.yugabyte.database=transaction_datastore
spark.cdm.connect.target.yugabyte.username=yugabyte
spark.cdm.connect.target.yugabyte.password=yugabyte
# Schema name (optional - defaults to "public" if not specified)
# spark.cdm.connect.target.yugabyte.schema=public

# =============================================================================
# SCHEMA CONFIGURATION
# =============================================================================
spark.cdm.schema.origin.keyspaceTable=transaction_datastore.dda_pstd_fincl_txn_cnsmr_by_accntnbr
spark.cdm.schema.target.keyspaceTable=transaction_datastore.dda_pstd_fincl_txn_cnsmr_by_accntnbr

# =============================================================================
# CONSTANT COLUMNS FEATURE - AUDIT FIELDS
# =============================================================================
# Populate audit fields that don't exist in source table
# These fields will be populated with constant values for all migrated records
spark.cdm.feature.constantColumns.names=z_audit_crtd_by_txt,z_audit_evnt_id,z_audit_crtd_ts,z_audit_last_mdfd_by_txt
spark.cdm.feature.constantColumns.values='CDM_MIGRATION','MIGRATION_BATCH_001','2024-12-17T10:00:00Z','CDM_MIGRATION'

# =============================================================================
# HIGH-PERFORMANCE SETTINGS (Phase 1+2 Optimizations)
# =============================================================================
# Phase 1: PreparedStatement reuse
# Phase 2: JDBC batching with rewriteBatchedInserts
spark.cdm.connect.target.yugabyte.batchSize=25
spark.cdm.connect.target.yugabyte.rewriteBatchedInserts=true
# Note: loadBalance disabled for local Docker (requires topologyKeys for multi-region)
spark.cdm.connect.target.yugabyte.loadBalance=false
spark.cdm.connect.target.yugabyte.prepareThreshold=5
spark.cdm.connect.target.yugabyte.socketTimeout=60000
spark.cdm.connect.target.yugabyte.tcpKeepAlive=true

# Connection Pool Settings
spark.cdm.connect.target.yugabyte.pool.maxSize=5
spark.cdm.connect.target.yugabyte.pool.minSize=2

# =============================================================================
# PERFORMANCE SETTINGS
# =============================================================================
# Optimized for small test (10 records)
spark.cdm.perfops.numParts=2
spark.cdm.perfops.batchSize=25
spark.cdm.perfops.ratelimit.origin=10000
spark.cdm.perfops.ratelimit.target=10000
spark.cdm.perfops.fetchSizeInRows=100

# Consistency Levels
spark.cdm.perfops.consistency.read=LOCAL_ONE
spark.cdm.perfops.consistency.write=LOCAL_QUORUM

# =============================================================================
# LOGGING
# =============================================================================
spark.cdm.log.directory=migration_logs
spark.cdm.log.level=INFO

# =============================================================================
# TRACKING (Optional - for resumable migrations)
# =============================================================================
spark.cdm.trackRun=false

