# =============================================================================
# CASSANDRA TO YUGABYTE YCQL MIGRATION CONFIGURATION
# =============================================================================
# This configuration migrates data from DataStax Cassandra to YugabyteDB YCQL
# YCQL uses the same CQL protocol as Cassandra, so we use standard Cassandra-to-Cassandra properties
#
# IMPORTANT: The same DataStax driver is used for both connections!
# - CDM uses Spark Cassandra Connector (which uses DataStax Java Driver 4.19.0)
# - Both origin (Cassandra) and target (Yugabyte YCQL) use the same CassandraConnector
# - Yugabyte YCQL is fully Cassandra-compatible, so no special driver is needed
#
# SSL Configuration: SSL is disabled by default. To enable SSL, uncomment and configure
# the TLS properties below. To explicitly disable SSL, leave them commented out.

# =============================================================================
# CASSANDRA SOURCE CONFIGURATION
# =============================================================================
spark.cdm.connect.origin.host=vcausc11udev057.azr.bank-dns.com
spark.cdm.connect.origin.port=9042
spark.cdm.connect.origin.username=cassandraappiduat
spark.cdm.connect.origin.password=Uat@123456
spark.cdm.connect.origin.localDC=datacenter1
spark.cdm.connect.origin.consistencyLevel=LOCAL_ONE

# =============================================================================
# YUGABYTE YCQL TARGET CONFIGURATION
# =============================================================================
# Note: YCQL uses port 9042 (same as Cassandra CQL port)
# Use standard target properties (not yugabyte-specific properties)
spark.cdm.connect.target.host=vcausc11udev057.azr.bank-dns.com
spark.cdm.connect.target.port=9042
spark.cdm.connect.target.username=yugabyte
spark.cdm.connect.target.password=password
# Optional: Set local datacenter if needed
# spark.cdm.connect.target.localDC=datacenter1
# spark.cdm.connect.target.consistencyLevel=LOCAL_ONE

# =============================================================================
# SCHEMA CONFIGURATION
# =============================================================================
spark.cdm.schema.origin.keyspaceTable=customer_datastore.customer_mtrc_by_lpid
spark.cdm.schema.target.keyspaceTable=customer_datastore.customer_mtrc_by_lpid

# =============================================================================
# SPARK CONFIGURATION
# =============================================================================
spark.executor.cores=4
spark.executor.instances=4
spark.executor.memory=6G
spark.driver.memory=6G
spark.sql.adaptive.enabled=true
spark.sql.adaptive.coalescePartitions.enabled=true
spark.sql.adaptive.skewJoin.enabled=true
spark.serializer=org.apache.spark.serializer.KryoSerializer
spark.sql.adaptive.advisoryPartitionSizeInBytes=32MB
spark.network.timeout=600s
spark.sql.broadcastTimeout=600s

# =============================================================================
# CDM PERFORMANCE CONFIGURATION
# =============================================================================
# Number of partitions
spark.cdm.perfops.numParts=400

# Rate limits
spark.cdm.perfops.ratelimit.origin=5000
spark.cdm.perfops.ratelimit.target=5000

# Batch size
spark.cdm.perfops.batchSize=5000

# Fetch size
spark.cdm.perfops.fetchSizeInRows=5000

# =============================================================================
# CONNECTION SETTINGS
# =============================================================================
spark.cdm.connect.origin.timeout=120000
spark.cdm.connect.target.timeout=120000

# Spark Cassandra Connector connection settings (for troubleshooting connection issues)
# These settings help with "Lost connection to remote peer" and "Could not reach any contact point" errors
spark.cassandra.connection.timeout.ms=30000
spark.cassandra.connection.keep_alive_ms=30000
spark.cassandra.connection.local_dc=datacenter1
spark.cassandra.connection.reconnection_delay_ms.min=1000
spark.cassandra.connection.reconnection_delay_ms.max=60000
spark.cassandra.connection.max_requests_per_connection.local=32768
spark.cassandra.connection.max_requests_per_connection.remote=2000
spark.cassandra.connection.factory=com.datastax.spark.connector.cql.DefaultConnectionFactory

# =============================================================================
# SSL/TLS CONFIGURATION (OPTIONAL - DISABLED BY DEFAULT)
# =============================================================================
# SSL is DISABLED by default. To bypass SSL, leave these properties commented out.
# If you need to enable SSL, uncomment and configure the properties below.

# Origin (Cassandra) SSL Configuration
# spark.cdm.connect.origin.tls.enabled=false
# spark.cdm.connect.origin.tls.trustStore.path=
# spark.cdm.connect.origin.tls.trustStore.password=
# spark.cdm.connect.origin.tls.trustStore.type=JKS
# spark.cdm.connect.origin.tls.keyStore.path=
# spark.cdm.connect.origin.tls.keyStore.password=
# spark.cdm.connect.origin.tls.enabledAlgorithms=TLS_RSA_WITH_AES_128_CBC_SHA,TLS_RSA_WITH_AES_256_CBC_SHA

# Target (Yugabyte YCQL) SSL Configuration
# For detailed instructions on setting up truststore.jks, see YUGABYTE_YCQL_SSL_SETUP.md
# 
# Quick setup:
#   1. Get root certificate: scp user@yugabyte-node:/opt/yugabyte/tls/certs/ca.crt ./ca.crt
#   2. Create truststore: keytool -importcert -alias yugabyte-root-ca -file ca.crt \
#      -keystore truststore.jks -storetype JKS -storepass YourPassword -noprompt
#   3. Uncomment and configure the properties below
#
# spark.cdm.connect.target.tls.enabled=true
# spark.cdm.connect.target.tls.trustStore.path=/path/to/truststore.jks
# spark.cdm.connect.target.tls.trustStore.password=YourTruststorePassword
# spark.cdm.connect.target.tls.trustStore.type=JKS
# spark.cdm.connect.target.tls.keyStore.path=
# spark.cdm.connect.target.tls.keyStore.password=
# spark.cdm.connect.target.tls.enabledAlgorithms=TLS_RSA_WITH_AES_128_CBC_SHA,TLS_RSA_WITH_AES_256_CBC_SHA

# =============================================================================
# AUTOCORRECT AND TRACKING
# =============================================================================
spark.cdm.autocorrect.missing=false
spark.cdm.autocorrect.mismatch=false
spark.cdm.trackRun=false
# spark.cdm.trackRun.runId=0
# spark.cdm.trackRun.previousRunId=0

# =============================================================================
# LOGGING
# =============================================================================
spark.cdm.log.directory=migration_logs
spark.cdm.log.level=INFO

