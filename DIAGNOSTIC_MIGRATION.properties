# =============================================================================
# DIAGNOSTIC MIGRATION CONFIGURATION
# =============================================================================
# This configuration helps identify performance bottlenecks
# Uses minimal parallelism to isolate the issue

# =============================================================================
# CASSANDRA SOURCE CONFIGURATION
# =============================================================================
spark.cdm.connect.origin.host=vcausc11udev057.azr.bank-dns.com
spark.cdm.connect.origin.port=9042
spark.cdm.connect.origin.username=cassandraappiduat
spark.cdm.connect.origin.password=Uat@123456
spark.cdm.connect.origin.localDC=datacenter1
spark.cdm.connect.origin.consistencyLevel=LOCAL_ONE

# =============================================================================
# YUGABYTEDB TARGET CONFIGURATION
# =============================================================================
spark.cdm.connect.target.yugabyte.host=vcausc11udev057.azr.bank-dns.com
spark.cdm.connect.target.yugabyte.port=5433
spark.cdm.connect.target.yugabyte.database=cdmybtest
spark.cdm.connect.target.yugabyte.username=yugabyte
spark.cdm.connect.target.yugabyte.password=password

# =============================================================================
# SCHEMA CONFIGURATION
# =============================================================================
spark.cdm.schema.origin.keyspaceTable=customer_datastore.customer_mtrc_by_lpid
spark.cdm.schema.target.keyspaceTable=customer_datastore.customer_mtrc_by_lpid

# =============================================================================
# MINIMAL PARALLELISM (FOR DIAGNOSIS)
# =============================================================================
# Single executor to isolate the bottleneck
spark.executor.cores=1
spark.executor.instances=1
spark.executor.memory=2G
spark.driver.memory=2G

# Minimal partitions
spark.cdm.perfops.numParts=10

# =============================================================================
# CONNECTION TIMEOUT SETTINGS
# =============================================================================
spark.cdm.connect.origin.timeout=120000
spark.cdm.connect.target.yugabyte.timeout=120000

# =============================================================================
# RATE LIMITING (MINIMAL)
# =============================================================================
# Very low rate limits to test if rate limiting is the issue
spark.cdm.rate.origin.readsPerSecond=100
spark.cdm.rate.target.writesPerSecond=100

# =============================================================================
# BATCH PROCESSING (MINIMAL)
# =============================================================================
# Small batch sizes to test if batching is the issue
spark.cdm.perfops.batchSize=10
spark.cdm.batch.size=10
spark.cdm.fetch.size=10

# =============================================================================
# ERROR HANDLING AND LOGGING
# =============================================================================
spark.cdm.log.directory=migration_logs
spark.cdm.log.level=DEBUG

# =============================================================================
# SPARK CONFIGURATION (MINIMAL)
# =============================================================================
spark.sql.adaptive.enabled=false
spark.sql.adaptive.coalescePartitions.enabled=false
spark.sql.adaptive.skewJoin.enabled=false

# =============================================================================
# YUGABYTEDB SPECIFIC SETTINGS
# =============================================================================
# Minimal connection pool
spark.cdm.connect.target.yugabyte.maxConnections=1
spark.cdm.connect.target.yugabyte.connectionTimeout=60000
spark.cdm.connect.target.yugabyte.socketTimeout=120000

# =============================================================================
# NETWORK OPTIMIZATION
# =============================================================================
spark.network.timeout=600s
spark.sql.broadcastTimeout=600s
